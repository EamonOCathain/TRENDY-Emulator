{
  "model_info": "DistributedDataParallel(\n  (module): YearProcessor(\n    (inner): CustomTransformer(\n      (pre_conv): Sequential(\n        (0): Conv1d(70, 1024, kernel_size=(1,), stride=(1,))\n        (1): PReLU(num_parameters=1)\n        (2): Conv1d(1024, 384, kernel_size=(1,), stride=(1,))\n        (3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (pos_enc): PositionalEncoding(\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (transformer): TransformerEncoder(\n        (layers): ModuleList(\n          (0-3): 4 x TransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n            )\n            (linear1): Linear(in_features=128, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (linear2): Linear(in_features=512, out_features=128, bias=True)\n            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.1, inplace=False)\n            (dropout2): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (post_conv): Sequential(\n        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n        (1): PReLU(num_parameters=1)\n        (2): Conv1d(256, 15, kernel_size=(1,), stride=(1,))\n      )\n    )\n  )\n)",
  "train_loss": [
    0.0
  ],
  "val_loss": [
    8.475509544461966
  ],
  "val_loss_batches": [],
  "val_loss_steps": [],
  "batch_loss": [
    0.0
  ],
  "batch_step": [
    0
  ],
  "epoch_edges": [
    0,
    1
  ],
  "samples_seen": 5950,
  "lr_values": [],
  "lr_steps": [],
  "carry_stage_steps": [
    0
  ],
  "carry_stage_epochs": [
    0
  ],
  "carry_stage_values": [
    0.0
  ]
}