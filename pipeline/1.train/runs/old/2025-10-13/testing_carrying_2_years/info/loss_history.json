{
  "model_info": "DistributedDataParallel(\n  (module): YearProcessor(\n    (inner): CustomTransformer(\n      (pre_conv): Sequential(\n        (0): Conv1d(70, 1024, kernel_size=(1,), stride=(1,))\n        (1): PReLU(num_parameters=1)\n        (2): Conv1d(1024, 384, kernel_size=(1,), stride=(1,))\n        (3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (pos_enc): PositionalEncoding(\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (transformer): TransformerEncoder(\n        (layers): ModuleList(\n          (0-3): 4 x TransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n            )\n            (linear1): Linear(in_features=128, out_features=512, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (linear2): Linear(in_features=512, out_features=128, bias=True)\n            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.1, inplace=False)\n            (dropout2): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (post_conv): Sequential(\n        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n        (1): PReLU(num_parameters=1)\n        (2): Conv1d(256, 15, kernel_size=(1,), stride=(1,))\n      )\n    )\n  )\n)",
  "train_loss": [
    0.0043786322459622865
  ],
  "val_loss": [
    4.490585971764241
  ],
  "val_loss_batches": [],
  "val_loss_steps": [],
  "batch_loss": [
    0.0043786322459622865
  ],
  "batch_step": [
    0
  ],
  "epoch_edges": [
    0,
    1
  ],
  "samples_seen": 344064,
  "lr_values": [
    8.999999989447703e-05,
    8.999999957790813e-05,
    8.999999905029329e-05,
    8.999999831163253e-05,
    8.999999736192583e-05,
    8.999999620117319e-05,
    8.999999482937467e-05,
    8.999999324653022e-05,
    8.999999145263987e-05,
    8.999998944770362e-05,
    8.99999872317215e-05,
    8.99999848046935e-05,
    8.999998216661966e-05,
    8.999997931749997e-05,
    8.999997625733443e-05,
    8.99999729861231e-05,
    8.999996950386597e-05,
    8.999996581056305e-05,
    8.999996190621439e-05,
    8.999995779081998e-05,
    8.999995346437985e-05,
    8.999994892689403e-05,
    8.999994417836255e-05,
    8.99999392187854e-05,
    8.999993404816266e-05,
    8.999992866649431e-05,
    8.99999230737804e-05,
    8.999991727002094e-05,
    8.9999911255216e-05,
    8.999990502936557e-05,
    8.99998985924697e-05,
    8.999989194452843e-05,
    8.999988508554177e-05,
    8.999987801550977e-05,
    8.999987073443249e-05,
    8.999986324230993e-05,
    8.999985553914215e-05,
    8.999984762492919e-05,
    8.999983949967108e-05,
    8.999983116336788e-05,
    8.999982261601962e-05,
    8.999981385762636e-05,
    8.999980488818811e-05,
    8.999979570770494e-05
  ],
  "lr_steps": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41,
    42,
    43
  ],
  "carry_stage_steps": [
    0
  ],
  "carry_stage_epochs": [
    0
  ],
  "carry_stage_values": [
    2.0
  ]
}